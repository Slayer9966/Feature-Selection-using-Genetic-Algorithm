{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzLi8vuRSXj9",
        "outputId": "17dee67d-47f3-4319-daeb-bc56a668461d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def target_encode(X, y, column):\n",
        "\n",
        "    if column not in X.columns:\n",
        "        raise ValueError(f\"Column '{column}' not found in feature set X\")\n",
        "\n",
        "    X[column] = X[column].fillna('Missing')\n",
        "    temp_df = pd.concat([X, y], axis=1)\n",
        "\n",
        "    mean_encoding = temp_df.groupby(column)[y.name].mean()\n",
        "\n",
        "    X[column] = X[column].map(mean_encoding)\n",
        "    return X\n",
        "\n",
        "def load_data(filepath, target_column):\n",
        "    data = pd.read_csv(filepath)\n",
        "    print(target_column)\n",
        "    data.columns = data.columns.str.strip().str.replace(r'\\s+', '', regex=True)\n",
        "\n",
        "    print(\"First few rows of the dataset:\\n\", data.head())\n",
        "    print(\"\\nColumn names:\", data.columns)\n",
        "\n",
        "    if 'Unnamed: 0' in data.columns:\n",
        "        data = data.drop(columns=['Unnamed: 0'])\n",
        "\n",
        "    if target_column not in data.columns:\n",
        "        raise ValueError(f\"Target column '{target_column}' not found in the dataset.\")\n",
        "\n",
        "    X = data.drop(target_column, axis=1)\n",
        "    y = data[target_column]\n",
        "\n",
        "    categorical_columns = X.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "    for column in categorical_columns:\n",
        "        X = target_encode(X, y, column)\n",
        "\n",
        "    return train_test_split(X, y, test_size=0.2, random_state=42), X.columns.tolist()\n",
        "\n",
        "filepath = 'your csv file link'\n",
        "target_column = 'your target class'\n",
        "(X_train, X_test, y_train, y_test), feature_names = load_data(filepath, target_column)\n",
        "\n",
        "\n",
        "X_train.to_csv('processed_X_train.csv', index=False)\n",
        "X_test.to_csv('processed_X_test.csv', index=False)\n",
        "y_train.to_csv('processed_y_train.csv', index=False)\n",
        "y_test.to_csv('processed_y_test.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wF6nAEjWB8N4",
        "outputId": "23d36bea-04eb-4bdf-d732-68952b3c058a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from deap import base, creator, tools\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "if not hasattr(creator, \"FitnessMax\"):\n",
        "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "if not hasattr(creator, \"Individual\"):\n",
        "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "def get_correlation_scores(X_train, y_train):\n",
        "    correlations = X_train.corrwith(y_train).abs()\n",
        "    correlations = correlations / correlations.max()\n",
        "    return correlations\n",
        "\n",
        "def evaluate(individual, X_train, y_train, feature_names, correlation_scores):\n",
        "    selected_features = [feature_names[i] for i in range(len(individual)) if individual[i] == 1]\n",
        "\n",
        "    if len(selected_features) < 2:\n",
        "        return 0,  # Low score if fewer features are selected\n",
        "\n",
        "    # Calculate correlation-based fitness\n",
        "    selected_corr = correlation_scores[selected_features].sum()\n",
        "\n",
        "\n",
        "    X_selected = X_train[selected_features]\n",
        "    inter_correlation = X_selected.corr().abs().values\n",
        "    penalty = inter_correlation[np.triu_indices(len(selected_features), k=1)].mean()\n",
        "\n",
        "    fitness = selected_corr - penalty\n",
        "    return fitness,\n",
        "\n",
        "\n",
        "def genetic_feature_selection(X_train, y_train, feature_names, n_gen=50, pop_size=200, cxpb=0.7, mutpb=0.3):\n",
        "    correlation_scores = get_correlation_scores(X_train, y_train)\n",
        "\n",
        "    toolbox = base.Toolbox()\n",
        "    toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
        "    toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=len(feature_names))\n",
        "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "    toolbox.register(\"evaluate\", evaluate, X_train=X_train, y_train=y_train, feature_names=feature_names, correlation_scores=correlation_scores)\n",
        "    toolbox.register(\"mate\", tools.cxTwoPoint)\n",
        "    toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
        "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "\n",
        "    population = toolbox.population(n=pop_size)\n",
        "\n",
        "    for gen in range(n_gen):\n",
        "        print(f\"Generation {gen}\")\n",
        "\n",
        "        offspring = toolbox.select(population, len(population))\n",
        "        offspring = list(map(toolbox.clone, offspring))\n",
        "\n",
        "        for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
        "            if random.random() < cxpb:\n",
        "                toolbox.mate(child1, child2)\n",
        "                del child1.fitness.values\n",
        "                del child2.fitness.values\n",
        "\n",
        "        for mutant in offspring:\n",
        "            if random.random() < mutpb:\n",
        "                toolbox.mutate(mutant)\n",
        "                del mutant.fitness.values\n",
        "\n",
        "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
        "        fitnesses = map(toolbox.evaluate, invalid_ind)\n",
        "        for ind, fit in zip(invalid_ind, fitnesses):\n",
        "            ind.fitness.values = fit\n",
        "\n",
        "        population[:] = offspring\n",
        "\n",
        "        selected_counts = [sum(ind) for ind in population]\n",
        "        avg_selected = sum(selected_counts) / len(selected_counts)\n",
        "        print(f\"Average number of features selected: {avg_selected}\")\n",
        "\n",
        "    best_individual = tools.selBest(population, 1)[0]\n",
        "    selected_features = [feature_names[i] for i in range(len(best_individual)) if best_individual[i] == 1]\n",
        "\n",
        "    if len(selected_features) == 0:\n",
        "        print(\"Warning: No features were selected. Defaulting to the first feature.\")\n",
        "        selected_features = [feature_names[0]]\n",
        "\n",
        "    return selected_features\n",
        "\n",
        "X_train = pd.read_csv('processed_X_train.csv').drop(columns=['Unnamed: 0'], errors='ignore')\n",
        "X_test = pd.read_csv('processed_X_test.csv').drop(columns=['Unnamed: 0'], errors='ignore')\n",
        "y_train = pd.read_csv('processed_y_train.csv').squeeze()\n",
        "y_test = pd.read_csv('processed_y_test.csv').squeeze()\n",
        "\n",
        "print(\"Running Genetic Algorithm for Feature Selection...\")\n",
        "feature_names = X_train.columns.tolist()\n",
        "selected_features = genetic_feature_selection(X_train, y_train, feature_names)\n",
        "\n",
        "print(\"Selected Features:\", selected_features)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
